{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment nº2\n",
    "### Implementation and Analysis of Decision Tree Induction for Supervised Machine Learning\n",
    "#### Work assembled by Alejandro Gonçalves, Francisca Mihalache and Pedro Fernandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents <a name=\"contents\"></a>\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Datasets](#datasets)\n",
    "   - 2.1. [Restaurant](#restaurant1)\n",
    "   - 2.2. [Weather](#weather1)\n",
    "   - 2.3. [Iris](#iris1)\n",
    "   - 2.4. [Connect4](#connect41)\n",
    "3. [ID3](#id3)\n",
    "   - 3.1. [Entropy](#entropy)\n",
    "   - 3.2. [Information Gain](#information_gain)\n",
    "   - 3.3. [Example](#eg1)\n",
    "4. [ID3 Implementation](#id3-implementation)\n",
    "    - 4.1. [Restaurant](#restaurant2)\n",
    "    - 4.2. [Weather](#weather2)\n",
    "    - 4.3. [Iris](#iris2)\n",
    "    - 4.4. [Connect4](#connect42)\n",
    "5. [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "The goal is to implement the ID3 algorithm to learn decision trees from data, ensuring the program can both build the tree and classify new instances across different datasets, without using automatic libraries. The focus is on mastering the theoretical concepts and practically applying them to solve classification tasks effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "from collections import Counter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets <a name=\"datasets\"></a>\n",
    "[[go back to the top]](#contents)\n",
    "\n",
    "In this section, we will dive into the details of our datasets, exploring the nature of the data and the predictive outcomes they are associated with.\n",
    "\n",
    "**Note**: for those with ID's, that column is dropped, since it has no predictive value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant <a name=\"restaurant1\"></a>\n",
    "[[go back to the topic]](#datasets)\n",
    "\n",
    "This csv contains some examples of decision making. Given some information, the target is to decide whether the client waits or not.\n",
    "Each line, each instance contains 12 attributes, split among these categories.\n",
    "\n",
    "1. **Identification and Basic Information**:\n",
    "   - ID: Personal identifier for each restaurant entry.\n",
    "   - Type: Classification of the type of cuisine offered by the restaurant.\n",
    "\n",
    "2. **Dining Options within the Restaurant**:\n",
    "   - Alt: Availability of alternative dining options.\n",
    "   - Bar: Presence of a bar within the restaurant premises.\n",
    "\n",
    "3. **Temporal and Climate Conditions**:\n",
    "   - Fri: Indication of whether it is Friday or not.\n",
    "   - Rain: Weather condition, specifically rainy weather.\n",
    "\n",
    "4. **Customer Attributes**:\n",
    "   - Hun: Customer's hunger level.\n",
    "   - Pat: Patron density, indicating how crowded the restaurant is.\n",
    "\n",
    "5. **Service and Pricing**:\n",
    "   - Price: Price range of the restaurant.\n",
    "   - Res: Reservation availability for customers.\n",
    "\n",
    "6. **Wait Time**:\n",
    "   - Est: Estimated waiting time for a table.\n",
    "  \n",
    "7. **Decision Making**:\n",
    "   - Class: Target variable indicating whether a customer decides to wait for a table ('Yes') or not ('No').\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Checking and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Bar</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Hun</th>\n",
       "      <th>Pat</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Res</th>\n",
       "      <th>Type</th>\n",
       "      <th>Est</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>30-60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Some</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Burger</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>10-30</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Full</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>&gt;60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Alt  Bar  Fri  Hun   Pat Price Rain  Res    Type    Est Class\n",
       "0  X1  Yes   No   No  Yes  Some   $$$   No  Yes  French   0-10   Yes\n",
       "1  X2  Yes   No   No  Yes  Full     $   No   No    Thai  30-60    No\n",
       "2  X3   No  Yes   No   No  Some     $   No   No  Burger   0-10   Yes\n",
       "3  X4  Yes   No  Yes  Yes  Full     $   No   No    Thai  10-30   Yes\n",
       "4  X5  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60    No"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('restaurant.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values\n",
    "Checking if there's any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID       0\n",
      "Alt      0\n",
      "Bar      0\n",
      "Fri      0\n",
      "Hun      0\n",
      "Pat      0\n",
      "Price    0\n",
      "Rain     0\n",
      "Res      0\n",
      "Type     0\n",
      "Est      0\n",
      "Class    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping Booleans to Integers\n",
    "\n",
    "By replacing String values with small integers, it's easier for the program to process boolean values, and even the ones that have more than 2 options, for example the attribute **Price**.\n",
    "\n",
    "After the last evaluation, we need to handle the empty (None) values in the Pat attribute. (None != 'None').\n",
    "\n",
    "Again, if there is need to do so, just uncommenting what's below is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alt</th>\n",
       "      <th>Bar</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Hun</th>\n",
       "      <th>Pat</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Res</th>\n",
       "      <th>Type</th>\n",
       "      <th>Est</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>30-60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Some</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Burger</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>10-30</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Full</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>&gt;60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alt  Bar  Fri  Hun   Pat Price Rain  Res    Type    Est Class\n",
       "0  Yes   No   No  Yes  Some   $$$   No  Yes  French   0-10   Yes\n",
       "1  Yes   No   No  Yes  Full     $   No   No    Thai  30-60    No\n",
       "2   No  Yes   No   No  Some     $   No   No  Burger   0-10   Yes\n",
       "3  Yes   No  Yes  Yes  Full     $   No   No    Thai  10-30   Yes\n",
       "4  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60    No"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df1['Alt'] = df1['Alt'].replace({'No': '0', 'Yes': '1'})\n",
    "df1['Bar'] = df1['Bar'].replace({'No': 0, 'Yes': 1})\n",
    "df1['Fri'] = df1['Fri'].replace({'No': 0, 'Yes': 1})\n",
    "df1['Hun'] = df1['Hun'].replace({'No': 0, 'Yes': 1})\n",
    "df1['Rain'] = df1['Rain'].replace({'No': 0, 'Yes': 1})\n",
    "df1['Res'] = df1['Res'].replace({'No': 0, 'Yes': 1})\n",
    "df1['Class'] = df1['Class'].replace({'No': 0, 'Yes': 1})\n",
    "df1['Type'] = df1['Type'].replace({'French':0, 'Thai':1, 'Burger':2, 'Italian':3})\n",
    "\n",
    "'''\n",
    "#df1['Est'] = df1['Est'].replace({'0-10': 0, '10-30': 1, '30-60': 2, '>60': 3})\n",
    "#df1['Price'] = df1['Price'].replace({'$':0, '$$':1,'$$$':2})\n",
    "\n",
    "# trivial python implementation to solve the labels with empty values\n",
    "def map_pat_to_int(value):\n",
    "    mapping = {'None': 'None', 'Some': 'Some', 'Full': 'Full'}\n",
    "    return mapping.get(value, -1)  # return -1 for empty values\n",
    "\n",
    "df1['Pat'] = df1['Pat'].apply(map_pat_to_int)\n",
    "df1 = df1.drop('ID', axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather <a name=\"weather1\"></a>\n",
    "[[go back to the topic]](#datasets)\n",
    "\n",
    "The 'weather' dataset holds a range of meteorological conditions and their impact on the decision to engage in an outdoor activity (specifically playing a sport).\n",
    "\n",
    "1. **ID** - Unique instance identification\n",
    "  \n",
    "2. **Weather Conditions**\n",
    "   - Weather: sunny, overcast, rainy\n",
    "   - Temperature: temperature (F) value\n",
    "   - Humidity: percentage, ranging from 0-100\n",
    "   - Windy: presence or absence \n",
    "\n",
    "3. **Decision** - Play or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weather</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weather  Temp  Humidity  Windy Play\n",
       "0     sunny    85        85  False   no\n",
       "1     sunny    80        90   True   no\n",
       "2  overcast    83        86  False  yes\n",
       "3     rainy    70        96  False  yes\n",
       "4     rainy    68        80  False  yes"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('weather.csv')\n",
    "df2 = df2.drop('ID', axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "Checking if there's any missing values, if so, those need to be handled accordingly. (There are none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather     0\n",
      "Temp        0\n",
      "Humidity    0\n",
      "Windy       0\n",
      "Play        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris <a name=\"iris1\"></a>\n",
    "[[go back to the topic]](#datasets)\n",
    "\n",
    "The 'iris' dataset, which is renowned for its introdutory role in the ML world, records the morphological measurements of *Iris* flowers. The attributes recorded are the following: \n",
    "\n",
    " 1. **ID** - Unique instance identification\n",
    "  \n",
    "2. **Features**\n",
    "   - Sepal Length\n",
    "   - Petal Length\n",
    "   - Sepal Width\n",
    "   - Petal Width\n",
    "\n",
    "3. **Decision** - Decide which species (Iris-setosa, Iris-versicolor, or Iris-virginica) the instance belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepallength  sepalwidth  petallength  petalwidth            class\n",
       "0           5.1         3.5          1.4         0.2      Iris-setosa\n",
       "1           4.9         3.0          1.4         0.2      Iris-setosa\n",
       "2           4.7         3.2          1.3         0.2      Iris-setosa\n",
       "3           4.6         3.1          1.5         0.2      Iris-setosa\n",
       "4           5.0         3.6          1.4         0.2      Iris-setosa\n",
       "..          ...         ...          ...         ...              ...\n",
       "95          5.7         3.0          4.2         1.2  Iris-versicolor\n",
       "96          5.7         2.9          4.2         1.3  Iris-versicolor\n",
       "97          6.2         2.9          4.3         1.3  Iris-versicolor\n",
       "98          5.1         2.5          3.0         1.1  Iris-versicolor\n",
       "99          5.7         2.8          4.1         1.3  Iris-versicolor\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('iris.csv')\n",
    "df3 = df3.drop('ID', axis=1)\n",
    "df3.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values\n",
    "Checking if there's any missing values, we conclude that there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepallength    0\n",
      "sepalwidth     0\n",
      "petallength    0\n",
      "petalwidth     0\n",
      "class          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a **scatterplot matrix**\n",
    "Although not used, it's useful to check this datasets data properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7ba4d1353e20>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.pairplot(df3, hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for the Iris dataset**: after careful search andevaluation, we concluded that the dataset is already clean, without outliers. For that reason, no further issues considering the csv will take place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect4 <a name=\"connect41\"></a>\n",
    "[[go back to the topic]](#datasets)\n",
    "\n",
    "The 'connect4' csv consists of multiple instances representing endgame states of the Connect Four game. The objective is to use these configurations to predict the outcome of the game - whether it ends in a win for the first player, a win for the second player, or a draw. \n",
    "\n",
    "This dataset is different fundamentaly, it does not contain attributes, but only the final state and the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>0-5</th>\n",
       "      <th>0-4</th>\n",
       "      <th>0-3</th>\n",
       "      <th>0-2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-0</th>\n",
       "      <th>1-5</th>\n",
       "      <th>1-4</th>\n",
       "      <th>1-3</th>\n",
       "      <th>...</th>\n",
       "      <th>5-2</th>\n",
       "      <th>5-1</th>\n",
       "      <th>5-0</th>\n",
       "      <th>6-5</th>\n",
       "      <th>6-4</th>\n",
       "      <th>6-3</th>\n",
       "      <th>6-2</th>\n",
       "      <th>6-1</th>\n",
       "      <th>6-0</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID 0-5 0-4 0-3 0-2 0-1 0-0 1-5 1-4 1-3  ... 5-2 5-1 5-0 6-5 6-4 6-3 6-2  \\\n",
       "0   1   b   b   b   b   b   b   b   b   b  ...   b   b   b   b   b   b   b   \n",
       "1   2   b   b   b   b   b   b   o   b   b  ...   b   b   b   b   b   b   b   \n",
       "2   3   b   b   b   b   b   b   b   b   b  ...   b   b   b   b   b   b   b   \n",
       "3   4   o   b   b   b   b   b   b   b   b  ...   b   b   b   b   b   b   b   \n",
       "4   5   b   b   b   b   b   b   b   b   b  ...   b   b   b   o   b   b   b   \n",
       "5   6   b   b   b   b   b   b   x   b   b  ...   b   b   b   b   b   b   b   \n",
       "6   7   b   b   b   b   b   b   x   b   b  ...   b   b   b   b   b   b   b   \n",
       "7   8   b   b   b   b   b   b   x   o   b  ...   b   b   b   b   b   b   b   \n",
       "8   9   b   b   b   b   b   b   x   b   b  ...   b   b   b   b   b   b   b   \n",
       "9  10   o   b   b   b   b   b   x   b   b  ...   b   b   b   b   b   b   b   \n",
       "\n",
       "  6-1 6-0 result  \n",
       "0   b   b    win  \n",
       "1   b   b    win  \n",
       "2   b   b    win  \n",
       "3   b   b    win  \n",
       "4   b   b    win  \n",
       "5   b   b   draw  \n",
       "6   b   b    win  \n",
       "7   b   b    win  \n",
       "8   b   b    win  \n",
       "9   b   b    win  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('connect4.csv',header=0) \n",
    "expected_columns = [f\"{col}-{row}\" for col in range(0, 7) for row in range(5, -1, -1)] + ['result']\n",
    "\n",
    "try:\n",
    "    if df4.columns.tolist() != ['ID'] + expected_columns:\n",
    "        raise ValueError(\"Column headers do not match, attempting to reload without headers.\")\n",
    "except:\n",
    "    df4.columns = expected_columns\n",
    "    if 'ID' not in df4.columns:\n",
    "        df4.insert(0, 'ID', range(1, len(df4) + 1))\n",
    "\n",
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values\n",
    "No missing values, so no need to access that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID        0\n",
      "0-5       0\n",
      "0-4       0\n",
      "0-3       0\n",
      "0-2       0\n",
      "0-1       0\n",
      "0-0       0\n",
      "1-5       0\n",
      "1-4       0\n",
      "1-3       0\n",
      "1-2       0\n",
      "1-1       0\n",
      "1-0       0\n",
      "2-5       0\n",
      "2-4       0\n",
      "2-3       0\n",
      "2-2       0\n",
      "2-1       0\n",
      "2-0       0\n",
      "3-5       0\n",
      "3-4       0\n",
      "3-3       0\n",
      "3-2       0\n",
      "3-1       0\n",
      "3-0       0\n",
      "4-5       0\n",
      "4-4       0\n",
      "4-3       0\n",
      "4-2       0\n",
      "4-1       0\n",
      "4-0       0\n",
      "5-5       0\n",
      "5-4       0\n",
      "5-3       0\n",
      "5-2       0\n",
      "5-1       0\n",
      "5-0       0\n",
      "6-5       0\n",
      "6-4       0\n",
      "6-3       0\n",
      "6-2       0\n",
      "6-1       0\n",
      "6-0       0\n",
      "result    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df4.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 <a name=\"id3\"></a>\n",
    "[[go back to the top]](#contents)\n",
    "\n",
    "A instance of the class ID3 will be defined only by the dataframe. Then, since all datasets are built the same, and all functions and the class logic keep on using the target (last column) and the attributes (excluding 1st and last), we define those in the *__init__*.\n",
    "\n",
    "All methods will have a commentary below briefly describing each method. When placing the cursor on a function call, there is a small description that helps the orientation through the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3:\n",
    "    def __init__(self, df):\n",
    "        '''Initializes the class, defines the target and attributes subset.'''\n",
    "        self.df = df\n",
    "        # self.tree = self._build_tree(df) # Pedro -> didn't work because of the order of definitions in the notebook I think, the idea was to, when defining the ID3 instance, creating the tree immediatly\n",
    "        self.atts = df.columns.tolist()[0:-1] \n",
    "        self.target = df.columns.tolist()[-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID3 decision tree algorithm strategically employs Information Gain to identify optimal points for splitting the data during the tree-building process. This selection is crucial as it influences the algorithm's ability to accurately classify data.\n",
    "\n",
    " To quantify IG, he uses the concept of **Entropy**. By calculating Entropy, we can evaluate the effectiveness of each potential split in **reducing uncertainty**, guiding the decision tree to more effective and informed splits that **enhance classification performance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Entropy Calculation:\n",
    "- **Definition of Entropy:** Measures the amount of uncertainty in the dataset.\n",
    "- **Entropy Calculation Formula:**\n",
    "\n",
    "  $$ \n",
    "  \\text{Entropy}(S) = -\\sum_{i=1}^n p_i \\log_2(p_i) \n",
    "  $$\n",
    "  - **n:** Total number of classes in the target column.\n",
    "  - **p_i:** Probability of class i, or the ratio of \"number of rows with class i in the target column\" to the \"total number of rows\" in the dataset.\n",
    "  - **log_2(p_i):** Logarithm base 2 of p_i, used to calculate the entropy contribution of each class.\n",
    "\n",
    "\n",
    "#### Information Gain Assessment:\n",
    "- **Information Gain Calculation:** Determine the gain in information by computing the change in entropy before and after partitioning the dataset based on an attribute.\n",
    "\n",
    "  - **Information Gain Formula:**\n",
    "    $$\n",
    "    IG(S, A) = \\text{Entropy}(S)- \\sum \\left( \\frac{|S_v|}{|S|} \\cdot \\text{Entropy}(S_v) \\right)\n",
    "  $$\n",
    "    \n",
    "  In this formula:\n",
    "  - **S**  is the entire dataset.\n",
    "  - **A** is the attribute used for partitioning.\n",
    "  - **S_v**  is the size of the subset of S where the attribute A has value v.\n",
    "  - **|S|**  is the total size of the dataset.\n",
    "  - **Entropy(S)** is the entropy of the entire dataset S.\n",
    "  - **Entropy(S_v)** is the entropy of subset S_v. \n",
    "\n",
    "##### Attribute Selection:\n",
    "- **Optimal Attribute Choice:** Select the attribute with the maximal information gain for splitting. This is done by calculating the information gain for each attribute and comparing these values to identify the attribute that most effectively reduces uncertainty.\n",
    "\n",
    "##### Iterative Process:\n",
    "- **Repetition Until Completion:** Continuing the process iteratively, applying the steps of entropy calculation, information gain assessment, and attribute selection recursively on each subset of the dataset created by a decision node.\n",
    "\n",
    "- The process ends when all data at a node have the same class, no remaining attributes exist for further partitioning, or another stopping criterion is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Entropy <a name=\"entropy\"></a>\n",
    "[[go back to the topic]](#id3)\n",
    "\n",
    "In order to do so, here's an implementation in python which calculates the entropy given the different values parsed as a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass_counts = [25, 25]  \\nentropy = entropy(class_counts)\\nprint(f\"Entropy of the distribution is: {entropy}\")\\n'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ID3(ID3):\n",
    "    def _entropy(self, class_counts):\n",
    "        \"\"\"Return the entropy given a list with the class counts.\"\"\"\n",
    "        total = sum(class_counts) \n",
    "        if total == 0:\n",
    "            return 0 \n",
    "\n",
    "        entropy = 0\n",
    "        for count in class_counts:\n",
    "            if count > 0:\n",
    "                probability = count / total\n",
    "                entropy -= probability * math.log2(probability)\n",
    "        #print(class_counts)\n",
    "        return entropy\n",
    "\n",
    "'''\n",
    "class_counts = [25, 25]  \n",
    "entropy = entropy(class_counts)\n",
    "print(f\"Entropy of the distribution is: {entropy}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to parse all the class counts as a list, and compare the different entropies, to choose the one that properly divides the dataset the most.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Information Gain <a name=\"information_gain\"></a>\n",
    "[[go back to the topic]](#id3)\n",
    "\n",
    "Now, using the previous function, we need to calculate the information gain for splitting the tree using the attribute_name, and the target_name.\n",
    "\n",
    "Next, there is an implementation in *python* which calculates the IG given the previously stated arguments.\n",
    "\n",
    "The function starts by calculating the weighted entropy, doing the summatory described above, and then doing the formula below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def _calculate_entropy_of_split(self, df, target_attribute):\n",
    "        '''Auxiliar to _information_gain, parses the target att counts to entropy'''\n",
    "        counts = [len(df[df[target_attribute] == value]) for value in df[target_attribute].unique()]\n",
    "        return self._entropy(counts)\n",
    "\n",
    "    def _information_gain(self, df_subset, attribute_name):\n",
    "        '''Returns IG given the current subset and the attribute'''\n",
    "        total_entropy = self._calculate_entropy_of_split(df_subset, self.target)\n",
    "        weighted_entropy = 0\n",
    "\n",
    "        for value in df_subset[attribute_name].unique(): # for each unique value in the df_subset attribute\n",
    "            subset = df_subset[df_subset[attribute_name] == value] # \n",
    "            subset_entropy = self._calculate_entropy_of_split(subset, self.target)\n",
    "            weighted_entropy += (len(subset) / len(df_subset)) * subset_entropy\n",
    "\n",
    "        return total_entropy - weighted_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plurality Values\n",
    "\n",
    "According to page 660 of the manual, **if** there is need to break ties, we pick the **most common output value** among a set of examples.\n",
    "\n",
    "Panda module has a built-in function to order by the most common, so we just need to adapt it. Although not now, it might be used for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def _plurality_value(self, target_attribute):\n",
    "        \"\"\"Return the most common value in the target attribute.\"\"\"\n",
    "        return Counter(self.df[target_attribute]).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example <a name=\"eg1\"></a>\n",
    "[[go back to the topic]](#id3)\n",
    "\n",
    "Let's test the new function for the Restaurant csv, splitting on the **Alt** attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6]\n"
     ]
    }
   ],
   "source": [
    "column_name = 'Alt'\n",
    "\n",
    "unique_values = df1[column_name].unique()\n",
    "\n",
    "class_counts = []\n",
    "for arr in unique_values:\n",
    "    x = df1[df1[column_name] == arr].shape[0]\n",
    "    class_counts.append(x)\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are good to go.\n",
    "The entropy should be 1, as it splits the dataset evenly, but we will test the function now.\n",
    "\n",
    "Then, we can test the IG calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy for [6, 6] : 1.0\n"
     ]
    }
   ],
   "source": [
    "x = ID3(df1)\n",
    "entr = x._entropy(class_counts)\n",
    "print(f\"Entropy for {class_counts} : {entr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attribute with the maximum information gain: Pat (IG: 0.541)\n"
     ]
    }
   ],
   "source": [
    "x = ID3(df1)\n",
    "\n",
    "information_gains = {}\n",
    "\n",
    "for column in x.atts:\n",
    "    gain = x._information_gain(x.df, column)\n",
    "    information_gains[column] = gain\n",
    "\n",
    "# Choose the attribute with the highest information gain\n",
    "max_gain_attr = max(information_gains, key=information_gains.get)\n",
    "\n",
    "print(f\"\\nAttribute with the maximum information gain: {max_gain_attr} (IG: {information_gains[max_gain_attr]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IG associated with each attribute is represented in the table below, in which we can assess that in fact, Pat has the highest IG score.\n",
    "\n",
    "\n",
    "\n",
    "| **Attribute**  | Alt | Bar | Fri | Hun | Pat | Price | Rain | Res | Type | Est |\n",
    "|------------|-----|-----|-----|-----|-----|-------|------|-----|------|-----|\n",
    "| **Information Gain**  | 0.000 | 0.000 | 0.021 | 0.196 | 0.541 | 0.196 | 0.000 | 0.021 | 0.000 | 0.208 |\n",
    "\n",
    "\n",
    "\n",
    "Now we have the base working for the ID3 algorithm, and can calculate the IG of the attributes correctly in each instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the best attribute\n",
    "\n",
    "In order to do so, we just need to use the previously defined methods, to pick the index of the attribute with the highest IG. \n",
    "\n",
    "The ID3 method *choose_best_attribute* creates a dictionary that links all the (remaining) attributes to their respective IG, and returns the key (attribute name) of the one with the max IG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Attribute for Splitting: Pat\n"
     ]
    }
   ],
   "source": [
    "class ID3(ID3):\n",
    "    def choose_best_attribute(self, df_subset):    \n",
    "        \"\"\"Returns, given the subset, the name of the attribute with the highest IG.\"\"\"    \n",
    "        remaining_attributes = [col for col in df_subset.columns if col != self.target] # debug/double-checking step\n",
    "\n",
    "        information_gains = {} # dict att -> IG(att)\n",
    "        for attr in remaining_attributes:\n",
    "            information_gains[attr] = self._information_gain(df_subset, attr)\n",
    "\n",
    "        return max(information_gains, key=information_gains.get)\n",
    "\n",
    "a = ID3(df1)\n",
    "subset = a.df  # simulating the first iteration, therefore we use the entire dataset\n",
    "best_attribute = a.choose_best_attribute(subset)\n",
    "\n",
    "print(\"Best Attribute for Splitting:\", best_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 Implementation <a name=\"id3-implementation\"></a> \n",
    "[[go back to the top]](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Implementation <a name=\"restaurant2\"></a> \n",
    "\n",
    "This is the simplest one. No adaptations are required, since the **values are discrete**, and not continuous values, and the **target class is binary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def _build_tree(self, data):\n",
    "        \"\"\"Constructs the nested dictionary for a specific dataframe, has the argument data for the recursion matter.\"\"\"\n",
    "        # debug statements from chatGPT\n",
    "\n",
    "        labels = data[data.columns[-1]].tolist()\n",
    "        class_counts = Counter(labels)\n",
    "\n",
    "        # Base cases\n",
    "        if len(set(labels)) == 1:\n",
    "            return [labels[0], class_counts[labels[0]]]  # returned 2 thing to help the debug below\n",
    "        if len(data.columns) == 1:\n",
    "            return [class_counts.most_common(1)[0][0], len(labels)] \n",
    "\n",
    "        # Choose the best attribute to split on\n",
    "        best_attribute = self.choose_best_attribute(data)\n",
    "        node = {best_attribute: {}}\n",
    "\n",
    "        complete_values = self.df[best_attribute].unique() # since French was missing, we need another \"flag\"\n",
    "        subset_values = data[best_attribute].unique()\n",
    "        # print(f\"Building tree on {best_attribute}, values: {complete_values}\")\n",
    "        \n",
    "        # missing_values = set(complete_values) - set(subset_values)\n",
    "        # print(missing_values)\n",
    "\n",
    "        for value in complete_values:\n",
    "            subset = data[data[best_attribute] == value]\n",
    "            if subset.empty:\n",
    "                # Assign the majority class if this value is missing in the subset\n",
    "                majority_class = class_counts.most_common(1)[0][0]\n",
    "                # print(f\"Value '{value}' missing. Assigning majority class '{majority_class}'\")\n",
    "                node[best_attribute][value] = [majority_class, 0]\n",
    "            else:\n",
    "                # Recursively build the tree for non-empty subsets\n",
    "                remaining_data = subset.drop(columns=[best_attribute])\n",
    "                node[best_attribute][value] = self._build_tree(remaining_data)\n",
    "\n",
    "        return node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pat': {'Some': ['Yes', 4], 'Full': {'Hun': {'Yes': {'Type': {'French': ['No', 0], 'Thai': {'Fri': {'No': ['No', 1], 'Yes': ['Yes', 1]}}, 'Burger': ['Yes', 1], 'Italian': ['No', 1]}}, 'No': ['No', 2]}}, 'None': ['No', 2]}}\n"
     ]
    }
   ],
   "source": [
    "# test the function usage \n",
    "abc = ID3(df1)\n",
    "decision_tree_structure = abc._build_tree(abc.df)\n",
    "\n",
    "print(decision_tree_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can however define a recursive function with the corresponding indents, and make it look more like a tree. Since the formattation is not relevant to the project's objective, we used chatGPT to define the *_recursive_print_tree* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def print_tree(self, tree_structure):\n",
    "        \"\"\"Public method to print the tree. Needed to solve the issue with the arguments and recursions.\"\"\"\n",
    "        print(\"{\")\n",
    "        self._recursive_print_tree(tree_structure, \"  \")\n",
    "        print(\"}\")\n",
    "\n",
    "    def _recursive_print_tree(self, tree, prefix=\"\", indent=\"      \"):\n",
    "        \"\"\"Private method that prints the nested dictionary as a tree, recursively. The indent is increasable for aesthetic reasons.\"\"\"\n",
    "        if isinstance(tree, dict):\n",
    "            for attribute, branches in tree.items():\n",
    "                print(prefix + f\"'{attribute}': {{\")\n",
    "                last_value = len(branches) - 1\n",
    "\n",
    "                for index, (value, subtree) in enumerate(branches.items()):\n",
    "                    is_last = index == last_value\n",
    "                    value_prefix = prefix + indent\n",
    "\n",
    "                    if isinstance(subtree, dict):\n",
    "                        print(value_prefix + f\"'{value}': {{\")\n",
    "                        self._recursive_print_tree(subtree, value_prefix + indent, indent)\n",
    "                        print(value_prefix + \"}\" + (\",\" if not is_last else \"\"))\n",
    "                    else:\n",
    "                        # Leaf node handling\n",
    "                        leaf_value = subtree[0] if isinstance(subtree, list) else subtree\n",
    "                        print(value_prefix + f\"'{value}': '{leaf_value}'\" + (\",\" if not is_last else \"\"))\n",
    "\n",
    "                print(prefix + \"}\" + (\",\" if not is_last else \"\"))\n",
    "\n",
    "        else:\n",
    "            # Handle single-value leaf nodes\n",
    "            leaf_value = tree[0] if isinstance(tree, list) else tree\n",
    "            print(prefix + f\"'{leaf_value}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'Pat': {\n",
      "        'Some': 'Yes',\n",
      "        'Full': {\n",
      "              'Hun': {\n",
      "                    'Yes': {\n",
      "                          'Type': {\n",
      "                                'French': 'No',\n",
      "                                'Thai': {\n",
      "                                      'Fri': {\n",
      "                                            'No': 'No',\n",
      "                                            'Yes': 'Yes'\n",
      "                                      }\n",
      "                                },\n",
      "                                'Burger': 'Yes',\n",
      "                                'Italian': 'No'\n",
      "                          }\n",
      "                    },\n",
      "                    'No': 'No'\n",
      "              }\n",
      "        },\n",
      "        'None': 'No'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "teste = ID3(df1)\n",
    "decision_tree_structure = abc._build_tree(abc.df)\n",
    "teste.print_tree(decision_tree_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify examples for Restaurant\n",
    "\n",
    "We can create a new function, that iterates recursively the nested dictionary in order to classify a new example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def classify(self, instance, node=None): # Classify a new instance using the decision tree.\n",
    "        '''Given an instance defined in a dictionary, iterates through the dictionary to classify new examples.'''\n",
    "        if not isinstance(node, dict):\n",
    "            return node  # Leaf node with classification label\n",
    "        attribute = next(iter(node))\n",
    "        value = instance.get(attribute)\n",
    "        next_branch = node.get(attribute).get(value, 'Unknown')\n",
    "        if isinstance(next_branch, dict):\n",
    "            return self.classify(instance, next_branch) # Iterate recursively to the next branch\n",
    "        else:\n",
    "            return next_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can define a new instance, and given the generated tree, will take the proper decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do them wait for a table?: No\n"
     ]
    }
   ],
   "source": [
    "new_instance = {\n",
    "    'Alt': 'Yes',\n",
    "    'Bar': 'No',\n",
    "    'Fri': 'Yes',\n",
    "    'Hun': 'No',\n",
    "    'Pat': 'Full',\n",
    "    'Price': '$$$',\n",
    "    'Rain': 'No',\n",
    "    'Res': 'Yes',\n",
    "    'Type': 'Italian',\n",
    "    'Est': '10-30'\n",
    "}\n",
    "\n",
    "x = ID3(df1)\n",
    "pred1 = x.classify(new_instance, decision_tree_structure)[0]\n",
    "print(\"Do them wait for a table?:\", pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Implementation <a name=\"weather2\"></a> \n",
    "[[go back to the topic]](#id3-implementation)\n",
    "\n",
    "Now, instead of only having discrete values, they are now continuous, in the attributes **Temperature** and **Humidity**. In order to handle them, different rules must be written: instead of **choosing according to the value** we need to **find the best split value**, meaning the value in which the function splits the best.\n",
    "\n",
    "What this means is, instead of the only operator being \"=\" (eg: if 'Pat' = 'Some'), now there is <= and >, for example, if **Temperature<80**.\n",
    "\n",
    "*This notebook will be overwriting the ID3 class functions during the generalization process.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best split value\n",
    "\n",
    "There are several ways to choose the value to which we divide the class. For example, we can divide considering the **half of the interval range a-b**:\n",
    "\n",
    "$$\n",
    "\\text{α} = \\frac{{a + b}}{2}\n",
    "$$\n",
    "\n",
    "Another way is to use the value α such that the number of elements above and below it are equal.\n",
    "$$\n",
    "\\exists y \\text{ : } \\text{count}(X \\geq α) \\approx \\text{count}(X \\leq α)\n",
    "$$\n",
    "\n",
    "During this project we decided to **brute-force all possible values** already existing on that attribute, and choose the value α, that works on the highest information gain. To do so, we need to get all the values, divide into subsets and see which \"splitter\" works on the best IG.\n",
    "\n",
    "The approach was simple, in a copy, replace all the values above or below the split_value explicitly, and then parse those to the previous IG function. Although not optimal, the usage of *deepcopy* made easier for the project comprehension. \n",
    "\n",
    "To check if the replacement is produced properly, *uncomment all the code on the auxiliar function and run the next 2 code cells*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class ID3(ID3):\n",
    "    def _calculate_best_split_value_aux(self, df_subset, att, split_value):\n",
    "        '''Auxiliar method, given a df_subset, a numerical attribute and the split value, it replaces the values (makes them discrete), and proceeds to calculate the IG as usual.'''\n",
    "        df_copy = copy.deepcopy(df_subset)\n",
    "\n",
    "        print_once_bool = False # lazy way to not print the head of the df a lot of times, prints only once since subset gets shorter\n",
    "        if df_subset.equals(self.df):\n",
    "            print_once_bool = True\n",
    "\n",
    "        for index in df_copy.index:\n",
    "            if df_copy.loc[index, att] <= split_value:\n",
    "                df_copy.loc[index, att] = 'leq'\n",
    "            else:\n",
    "                df_copy.loc[index, att] = 'more'\n",
    "        '''\n",
    "        if (print_once_bool): # print only once, in the first iteration\n",
    "            print(split_value)\n",
    "            print(self.df.head(10))\n",
    "            print(\"\\n\")\n",
    "            print(df_copy.head(10)) \n",
    "            print(\"\\n---------------------------------------------------------------\\n\")\n",
    "        '''\n",
    "        return self._information_gain(df_copy, att)\n",
    "        \n",
    "        \n",
    "    def _calculate_best_split_value(self, df_subset, att):\n",
    "        '''Given a subset, and a numerical attribute, returns a tuple with the best split value, and the respective IG when it splits the dataset there.'''\n",
    "        unique_values = sorted(df_subset[att].unique()) # list with the sorted unique values\n",
    "        #print(unique_values) \n",
    "        best_split_value = None\n",
    "        best_ig = float('-inf')\n",
    "\n",
    "        for i in range(1, len(unique_values)):\n",
    "            #split_value = (unique_values[i]) \n",
    "            split_value = (unique_values[i-1] + unique_values[i]) / 2 # if we want the midpoint\n",
    "            ig = self._calculate_best_split_value_aux(df_subset, att, split_value)\n",
    "\n",
    "            #print(f\"Current best value: {best_split_value} (IG: {best_ig}), testing for {split_value}... obtained IG:{ig}\")\n",
    "            if ig > best_ig:\n",
    "                best_ig = ig\n",
    "                best_split_value = split_value\n",
    "\n",
    "        return best_split_value, best_ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function, creating a instance for the weather.csv dataframe and testing on the **Temp** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.0, 0.1134008641811034)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ID3(df2)\n",
    "test._calculate_best_split_value(test.df, 'Temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptations for the code to run on the Weather dataframe\n",
    "\n",
    "Using this new implemented logic, some changes are required:\n",
    "- the *_choose_best_atribute* should be changed, and perform the conversion of the column to parse it to the IG function properly;\n",
    "- the *_build_tree* method needs to be able to check the type of data, and:\n",
    "   - if **categorical**, proceeds normally to get the IG;\n",
    "   - if **numerical**, needs to get the IG by testing all the different split values.;\n",
    "- the *_print_tree* associated method needs to print with the operators formatted as well, this method doesn't need to be changed, but the *_build_tree* needs to set the keys of the dictionary already with the operators.\n",
    "\n",
    "We can test the new adapted function along the way:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def _choose_best_attribute(self, df_subset):        \n",
    "        \"\"\"Returns, given the subset, the name of the attribute with the highest IG.\"\"\"    \n",
    "        remaining_attributes = [col for col in df_subset.columns if col != self.target] # debug step\n",
    "\n",
    "        information_gains = {} # dict att -> IG(att)\n",
    "\n",
    "        for attr in remaining_attributes:\n",
    "            if df_subset[attr].dtype in ['int64', 'float64']:\n",
    "                #print(attr + ', value of the split: ' + str(self._calculate_best_split_value(df_subset, attr)[0]) + ' , IG of the split: ' + str(self._calculate_best_split_value(df_subset, attr)[1]))\n",
    "                information_gains[attr] = self._calculate_best_split_value(df_subset, attr)[1] # reminder that this method returns tuple(value, ig)\n",
    "            else:\n",
    "                information_gains[attr] =  self._information_gain(df_subset, attr)\n",
    "                #print(attr + ' with IG : ' + str(self._information_gain(df_subset, attr)))\n",
    "\n",
    "        return max(information_gains, key=information_gains.get)\n",
    "        # return best_attribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an instance for both **df1** and **df2**, and check if it's still all working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attribute with the highest IG is: Weather.\n"
     ]
    }
   ],
   "source": [
    "df1_inst = ID3(df1)\n",
    "df2_inst = ID3(df2)\n",
    "\n",
    "#print(df1_inst.choose_best_attribute(df1_inst.df))\n",
    "#print(df2_inst.target)\n",
    "print(f\"The attribute with the highest IG is: {df2_inst._choose_best_attribute(df2_inst.df)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def _build_tree(self, data):\n",
    "        \"\"\"Constructs the nested dictionary for a specific dataframe, has the argument data for the recursion matter.\"\"\"\n",
    "        labels = data[data.columns[-1]].tolist()\n",
    "        class_counts = Counter(labels)\n",
    "\n",
    "        # Base cases\n",
    "        if len(set(labels)) == 1:\n",
    "            return [labels[0], class_counts[labels[0]]]\n",
    "        if len(data.columns) == 1:\n",
    "            return [class_counts.most_common(1)[0][0], len(labels)]\n",
    "\n",
    "        # Choose the best attribute to split on\n",
    "        best_attribute = self._choose_best_attribute(data)\n",
    "        node = {best_attribute: {}}\n",
    "\n",
    "        # case 1 - continuous attributes separately\n",
    "        if data[best_attribute].dtype in ['int64', 'float64']:\n",
    "            best_split_value = self._calculate_best_split_value(data, best_attribute)[0] # since _calculate_best_split_value returns a tuple\n",
    "            subset1 = data[data[best_attribute] <= best_split_value]\n",
    "            subset2 = data[data[best_attribute] > best_split_value]\n",
    "            node[best_attribute]['<= ' + str(best_split_value)] = self._build_tree(subset1)\n",
    "            node[best_attribute]['> ' + str(best_split_value)] = self._build_tree(subset2)\n",
    "\n",
    "        # case 2 - discrete attributes, previous logic\n",
    "        else:\n",
    "            complete_values = self.df[best_attribute].unique()\n",
    "            for value in complete_values:\n",
    "                subset = data[data[best_attribute] == value]\n",
    "\n",
    "                if subset.empty:\n",
    "                    # Assign the majority class if the value is missing\n",
    "                    majority_class = class_counts.most_common(1)[0][0]\n",
    "                    node[best_attribute][value] = [majority_class, 0]\n",
    "                else:\n",
    "                    remaining_data = subset.drop(columns=[best_attribute])\n",
    "                    node[best_attribute][value] = self._build_tree(remaining_data)\n",
    "\n",
    "        return node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the updates, we can build the tree, using the same print_tree function as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'Weather': {\n",
      "        'sunny': {\n",
      "              'Humidity': {\n",
      "                    '<= 77.5': 'yes',\n",
      "                    '> 77.5': 'no'\n",
      "              }\n",
      "        },\n",
      "        'overcast': 'yes',\n",
      "        'rainy': {\n",
      "              'Windy': {\n",
      "                    'False': 'yes',\n",
      "                    'True': 'no'\n",
      "              }\n",
      "        }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "teste2 = ID3(df2)\n",
    "decision_tree_structure2 = teste2._build_tree(teste2.df)\n",
    "teste2.print_tree(decision_tree_structure2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify new examples, we need to adapt the *_classify* method to handle continuous values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def classify(self, instance, node=None):\n",
    "        '''Given an instance defined in a dictionary, iterates through the dictionary to classify new examples.'''\n",
    "        if not isinstance(node, dict):\n",
    "            return node[0]  # return the classification label\n",
    "\n",
    "        attribute = next(iter(node)) \n",
    "        if attribute in instance:  \n",
    "            attribute_value = instance[attribute] \n",
    "\n",
    "            # check for continuous or discrete attribute handling, and check operator within the key\n",
    "            if isinstance(attribute_value, (int, float)):  \n",
    "                for key in node[attribute]:\n",
    "                    if \"<=\" in key:\n",
    "                        split_value = float(key.split('<= ')[1])\n",
    "                        if attribute_value <= split_value:\n",
    "                            return self.classify(instance, node[attribute][key])\n",
    "                    elif \">\" in key:\n",
    "                        split_value = float(key.split('> ')[1])\n",
    "                        if attribute_value > split_value:\n",
    "                            return self.classify(instance, node[attribute][key])\n",
    "            else: # discrete, same logic as before\n",
    "                next_branch = node[attribute].get(attribute_value, 'Unknown')\n",
    "                if isinstance(next_branch, dict):\n",
    "                    return self.classify(instance, next_branch)  \n",
    "                else:\n",
    "                    # Correct handling of leaf nodes when not a dictionary\n",
    "                    return next_branch[0] if next_branch != 'Unknown' else 'Unknown'\n",
    "\n",
    "        return 'Unknown'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does he/she play with those conditions?: no\n"
     ]
    }
   ],
   "source": [
    "new_instance_2 = {\n",
    "    'Weather': 'sunny',\n",
    "    'Temp': 80,\n",
    "    'Humidity': 90,\n",
    "    'Windy': 'true'\n",
    "}\n",
    "\n",
    "y = ID3(df2)  # Ensure that y.tree is properly initialized with the decision tree\n",
    "classification_result = y.classify(new_instance_2, decision_tree_structure2)\n",
    "print(\"Does he/she play with those conditions?:\", classification_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Implementation <a name=\"iris2\"></a> \n",
    "[[go back to the topic]](#id3-implementation)\n",
    "\n",
    "The key difference between this dataset and the previous 2 is that the **target class is non binary** (3 species). Although ID3 is essentially a binary classifier, we can extend and its logic to go around this problem.\n",
    "\n",
    "The simple application of what we had before, up until now results in the following tree:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'petallength': {\n",
      "        '<= 2.45': 'Iris-setosa',\n",
      "        '> 2.45': {\n",
      "              'petalwidth': {\n",
      "                    '<= 1.75': {\n",
      "                          'petallength': {\n",
      "                                '<= 4.95': {\n",
      "                                      'petalwidth': {\n",
      "                                            '<= 1.65': 'Iris-versicolor',\n",
      "                                            '> 1.65': 'Iris-virginica'\n",
      "                                      }\n",
      "                                },\n",
      "                                '> 4.95': {\n",
      "                                      'petalwidth': {\n",
      "                                            '<= 1.55': 'Iris-virginica',\n",
      "                                            '> 1.55': {\n",
      "                                                  'sepallength': {\n",
      "                                                        '<= 6.95': 'Iris-versicolor',\n",
      "                                                        '> 6.95': 'Iris-virginica'\n",
      "                                                  }\n",
      "                                            }\n",
      "                                      }\n",
      "                                }\n",
      "                          }\n",
      "                    },\n",
      "                    '> 1.75': {\n",
      "                          'petallength': {\n",
      "                                '<= 4.85': {\n",
      "                                      'sepallength': {\n",
      "                                            '<= 5.95': 'Iris-versicolor',\n",
      "                                            '> 5.95': 'Iris-virginica'\n",
      "                                      }\n",
      "                                },\n",
      "                                '> 4.85': 'Iris-virginica'\n",
      "                          }\n",
      "                    }\n",
      "              }\n",
      "        }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "teste3 = ID3(df3)\n",
    "decision_tree_structure3 = teste3._build_tree(teste3.df)\n",
    "teste3.print_tree(decision_tree_structure3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the tree is generated in some sense, it is wrong, since the code is made for binary targets.\n",
    "The methodology we'll perform first is to adapt the code for ONE *vs* ALL trees.\n",
    "\n",
    "Meaning we added a change to make it work and \"callable\":\n",
    "- Essencially, we will create 3 copies of the dataframe df3, each one for each possible species target;\n",
    "- then we will replace explicitly the target column values\n",
    "  - let's assume the target is *'Iris-Setosa'*\n",
    "  - the copy of the dataframe will replace the other 2 species with the same name, eg.: 'not-Iris-Setosa'\n",
    "  - the tree generated will then have a binary target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_setosa = deepcopy(df3)\n",
    "df3_versicolor = deepcopy(df3)\n",
    "df3_virginica = deepcopy(df3)\n",
    "\n",
    "# make the target binary, in a 1v2 way\n",
    "df3_setosa['class'] = df3_setosa['class'].where(df3_setosa['class'] == 'Iris-setosa', 'Not-Iris-Setosa')\n",
    "df3_versicolor['class'] = df3_versicolor['class'].where(df3_versicolor['class'] == 'Iris-versicolor', 'Not-Iris-versicolor')\n",
    "df3_virginica['class'] = df3_virginica['class'].where(df3_virginica['class'] == 'Iris-virginica', 'Not-Iris-virginica')\n",
    "\n",
    "# create instances for each \n",
    "inst_setosa = ID3(df3_setosa)\n",
    "inst_versicolor = ID3(df3_versicolor)\n",
    "inst_virginica = ID3(df3_virginica)\n",
    "\n",
    "# create dt structures\n",
    "tree3_1 = inst_setosa._build_tree(inst_setosa.df)\n",
    "tree3_2 = inst_versicolor._build_tree(inst_versicolor.df)\n",
    "tree3_3 = inst_virginica._build_tree(inst_virginica.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris setosa tree: \n",
      "{\n",
      "  'petallength': {\n",
      "        '<= 2.45': 'Iris-setosa',\n",
      "        '> 2.45': 'Not-Iris-Setosa'\n",
      "  }\n",
      "}\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Iris versicolor tree: \n",
      "{\n",
      "  'petallength': {\n",
      "        '<= 2.45': 'Not-Iris-versicolor',\n",
      "        '> 2.45': {\n",
      "              'petalwidth': {\n",
      "                    '<= 1.75': {\n",
      "                          'petallength': {\n",
      "                                '<= 4.95': {\n",
      "                                      'petalwidth': {\n",
      "                                            '<= 1.65': 'Iris-versicolor',\n",
      "                                            '> 1.65': 'Not-Iris-versicolor'\n",
      "                                      }\n",
      "                                },\n",
      "                                '> 4.95': {\n",
      "                                      'petalwidth': {\n",
      "                                            '<= 1.55': 'Not-Iris-versicolor',\n",
      "                                            '> 1.55': {\n",
      "                                                  'sepallength': {\n",
      "                                                        '<= 6.95': 'Iris-versicolor',\n",
      "                                                        '> 6.95': 'Not-Iris-versicolor'\n",
      "                                                  }\n",
      "                                            }\n",
      "                                      }\n",
      "                                }\n",
      "                          }\n",
      "                    },\n",
      "                    '> 1.75': {\n",
      "                          'petallength': {\n",
      "                                '<= 4.85': {\n",
      "                                      'sepallength': {\n",
      "                                            '<= 5.95': 'Iris-versicolor',\n",
      "                                            '> 5.95': 'Not-Iris-versicolor'\n",
      "                                      }\n",
      "                                },\n",
      "                                '> 4.85': 'Not-Iris-versicolor'\n",
      "                          }\n",
      "                    }\n",
      "              }\n",
      "        }\n",
      "  }\n",
      "}\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Iris virginica tree: \n",
      "{\n",
      "  'petallength': {\n",
      "        '<= 4.75': {\n",
      "              'petalwidth': {\n",
      "                    '<= 1.65': 'Not-Iris-virginica',\n",
      "                    '> 1.65': 'Iris-virginica'\n",
      "              }\n",
      "        },\n",
      "        '> 4.75': {\n",
      "              'petalwidth': {\n",
      "                    '<= 1.75': {\n",
      "                          'petallength': {\n",
      "                                '<= 4.95': 'Not-Iris-virginica',\n",
      "                                '> 4.95': {\n",
      "                                      'petalwidth': {\n",
      "                                            '<= 1.55': 'Iris-virginica',\n",
      "                                            '> 1.55': {\n",
      "                                                  'sepallength': {\n",
      "                                                        '<= 6.95': 'Not-Iris-virginica',\n",
      "                                                        '> 6.95': 'Iris-virginica'\n",
      "                                                  }\n",
      "                                            }\n",
      "                                      }\n",
      "                                }\n",
      "                          }\n",
      "                    },\n",
      "                    '> 1.75': {\n",
      "                          'petallength': {\n",
      "                                '<= 4.85': {\n",
      "                                      'sepallength': {\n",
      "                                            '<= 5.95': 'Not-Iris-virginica',\n",
      "                                            '> 5.95': 'Iris-virginica'\n",
      "                                      }\n",
      "                                },\n",
      "                                '> 4.85': 'Iris-virginica'\n",
      "                          }\n",
      "                    }\n",
      "              }\n",
      "        }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print the trees\n",
    "print(\"Iris setosa tree: \")\n",
    "inst_setosa.print_tree(tree3_1)\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(\"Iris versicolor tree: \")\n",
    "inst_versicolor.print_tree(tree3_2)\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(\"Iris virginica tree: \")\n",
    "inst_virginica.print_tree(tree3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the new instances, we can use the function, to test a new instance with the instances represented in the dictionary as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the instance a Iris-setosa?: Yes\n"
     ]
    }
   ],
   "source": [
    "new_instance_3 = {\n",
    "    'sepallength': 4.8,\n",
    "    'sepalwidth': 3.1,\n",
    "    'petallength': 1.6,\n",
    "    'petalwidth': 0.2\n",
    "}\n",
    "\n",
    "z = ID3(df3)  # Ensure that y.tree is properly initialized with the decision tree\n",
    "classification_result_setosa = inst_setosa.classify(new_instance_3, tree3_1)\n",
    "res = 'Yes' if classification_result_setosa == 'Iris-setosa' else 'No'\n",
    "print(\"Is the instance a Iris-setosa?:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to use all the datasets, and try to return an **answer that is coherent with all the trees**. Meaning the input can/will be accepted only when it is in accordance with the 3 trees.\n",
    "\n",
    "This will be achieved in the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-> Iris-setosa\n",
      "2-> Not-Iris-versicolor\n",
      "3-> Not-Iris-virginica\n",
      "\n",
      "Valid classification.\n"
     ]
    }
   ],
   "source": [
    "# the 3 tree structures are stored in tree3_1, tree3_2, tree3_3\n",
    "\n",
    "'''\n",
    "# code above as a reminder\n",
    "inst_setosa = ID3(df3_setosa)\n",
    "inst_versicolor = ID3(df3_versicolor)\n",
    "inst_virginica = ID3(df3_virginica)\n",
    "'''\n",
    "\n",
    "new_instance_3 = {\n",
    "    'sepallength': 4.8,\n",
    "    'sepalwidth': 3.1,\n",
    "    'petallength': 1.6,\n",
    "    'petalwidth': 0.2\n",
    "}\n",
    "\n",
    "# booleans definition\n",
    "isSetosa = False\n",
    "isVersicolor = False\n",
    "isVirginica = False\n",
    "\n",
    "for specie in ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']:\n",
    "    if 'setosa' in specie:\n",
    "        classification_result_setosa = inst_setosa.classify(new_instance_3, tree3_1)\n",
    "        print('1->', classification_result_setosa)\n",
    "        isSetosa = True if classification_result_setosa == 'Iris-setosa' else False\n",
    "    if 'versicolor' in specie:\n",
    "        classification_result_versicolor = inst_versicolor.classify(new_instance_3, tree3_2)\n",
    "        print('2->', classification_result_versicolor)\n",
    "        isVersicolor = True if classification_result_versicolor == 'Iris-versicolor' else False\n",
    "    if 'virginica' in specie:\n",
    "        classification_result_virginica = inst_virginica.classify(new_instance_3, tree3_3)\n",
    "        print('3->', classification_result_virginica)\n",
    "        isVirginica = True if classification_result_virginica == 'Iris-virginica' else False\n",
    "\n",
    "num_trues = sum(x for x in [isSetosa, isVersicolor, isVirginica]) # sum of true values\n",
    "\n",
    "if num_trues == 1:\n",
    "    print(\"\\nValid classification.\")\n",
    "else:\n",
    "    print(\"\\nInvalid classification.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "\n",
    "## -------------To-Do after-----------------\n",
    "To double-check and evaluate the performance of those trees, is (since the dataset is bigger than previously) to **perform a train/test split**, to evaluate the accuracy of the decision tree created.\n",
    "\n",
    "The train_test split will be performed manually, without the use of *sklearn* module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3(ID3):\n",
    "    def _score(self, test_split_frac = 0.5, random_seed = 99, shuffle_bool = True):\n",
    "        \"\"\"Return the percentage/fraction of the correctly assigned classes\"\"\"\n",
    "        copy_df = deepcopy(self.df)\n",
    "        copy_target = deepcopy(self.atts)\n",
    "\n",
    "        # randomize the dataset and the target with the same order\n",
    "        copy_df = copy_df.sample(random_seed).reset_index(drop=True)\n",
    "        copy_target = copy_target.sample(random_seed).reset_index(drop=True)\n",
    "\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect-4 Implementation\n",
    "\n",
    "This is the hardest part of the project. We need to create a class capable of holding the connect-4 game logic, and for that, we will be reusing the last project's code.\n",
    "\n",
    "Again, if we go and define a DT with no changes, a tree is generated, although its value is not relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df4.sample(n=100, random_state=42) \n",
    "\n",
    "t4 = ID3(df_sampled)\n",
    "dt4 = t4._build_tree(df_sampled)\n",
    "#t4.print_tree(dt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the class Game, used on the other work. For that reason, we won't lose much time explaining the code, since that is NOT this project's objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, board = [['-' for _ in range(7)] for _ in range(6)], turn = 'X'):\n",
    "        self.board = board\n",
    "        self.turn = turn\n",
    "\n",
    "    def printer(self):\n",
    "        print(\" \".join([str(i) for i in range(7)]))\n",
    "        for line in self.board:\n",
    "            print(' '.join(line))\n",
    "\n",
    "    def swap(self):\n",
    "        if self.turn == 'X':\n",
    "            self.turn = 'O'\n",
    "        else:\n",
    "            self.turn = 'X'\n",
    "\n",
    "    def copy(self):\n",
    "        new_game = copy.deepcopy(self)\n",
    "        return new_game\n",
    "    \n",
    "    def full(self):\n",
    "        row1 = self.board[0] #only first row required, since it's impossible to have blank spaces in the middle of the board\n",
    "        if '-' in row1:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def check_line(self, line): \n",
    "        countX = 0\n",
    "        countO = 0\n",
    "        for i in range(len(line)):\n",
    "            if line[i] == 'X':\n",
    "                countX += 1\n",
    "                countO = 0\n",
    "            elif line[i] == 'O':\n",
    "                countO += 1\n",
    "                countX = 0\n",
    "            else:\n",
    "                countX = 0\n",
    "                countO = 0\n",
    "\n",
    "            if countX == 4:\n",
    "                return 'X'\n",
    "            elif countO == 4:\n",
    "                return 'O'\n",
    "        \n",
    "        return '-'\n",
    "    \n",
    "    def check_win(self):\n",
    "        # Check rows\n",
    "        for row in self.board:\n",
    "            result = self.check_line(row)\n",
    "            if result != '-':\n",
    "                return result\n",
    "\n",
    "        # Check columns\n",
    "        for i in range(7):\n",
    "            column = [self.board[j][i] for j in range(6)]\n",
    "            result = self.check_line(column)\n",
    "            if result != '-':\n",
    "                return result\n",
    "\n",
    "        # Check main diagonals /\n",
    "        main_diagonal_indices = [(2, 0), (1, 0), (0, 0), (0, 1), (0, 2), (0, 3)]\n",
    "        for start_row, start_col in main_diagonal_indices:\n",
    "            diagonal = []\n",
    "            i, j = start_row, start_col\n",
    "            while 0 <= i < 6 and 0 <= j < 7:\n",
    "                diagonal.append(self.board[i][j])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            result = self.check_line(diagonal)\n",
    "            if result != '-':\n",
    "                return result\n",
    "\n",
    "        # Check inverse diagonals \\\n",
    "        inverse_diagonal_indices = [(0, 3), (0, 4), (0, 5), (0, 6), (1, 6), (2, 6)]\n",
    "        for start_row, start_col in inverse_diagonal_indices:\n",
    "            diagonal = []\n",
    "            i, j = start_row, start_col\n",
    "            while 0 <= i < 6 and 0 <= j < 7:\n",
    "                diagonal.append(self.board[i][j])\n",
    "                i += 1\n",
    "                j -= 1\n",
    "            result = self.check_line(diagonal)\n",
    "            if result != '-':\n",
    "                return result\n",
    "\n",
    "        return 'U' # unclear winner until the moment\n",
    "    \n",
    "    def available_cols(self):\n",
    "        available_cols = []\n",
    "        for col in range(7):\n",
    "            if self.board[0][col] == '-':  \n",
    "                available_cols.append(col)\n",
    "        return available_cols\n",
    "\n",
    "    def isFinished(self):\n",
    "        if not self.full() and self.check_win()=='U':\n",
    "            return False \n",
    "        return True\n",
    "    \n",
    "    def play_pvp(self):\n",
    "        while not self.isFinished():\n",
    "            self.printer()\n",
    "            choice = int(input(f\"It is now {self.turn}'s turn.\\nMake a move by choosing your coordinates to play:\" ))\n",
    "            while not (0 <= choice < 7) or choice not in self.available_cols():                \n",
    "                choice = int(input(f\"Invalid move.\\nMake a move by choosing your coordinates to play:\" ))\n",
    "            self.make_move(choice)\n",
    "            self.swap()\n",
    "            # Check for a winner after each move\n",
    "            winner = self.check_win()\n",
    "            if winner == 'O':\n",
    "                self.printer()\n",
    "                print(\"O won!\")\n",
    "            elif winner == 'X':\n",
    "                self.printer()\n",
    "                print(\"X won!\")\n",
    "            elif self.isFinished() and winner == '-':\n",
    "                self.printer()\n",
    "                print(\"It's a tie!\")\n",
    "\n",
    "    def undo_move(self, c):\n",
    "        for i in range(6):\n",
    "            if self.board[i][c] != '-':\n",
    "                self.board[i][c] = '-'\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def make_move(self, y): \n",
    "        if self.board[0][y] != '-':\n",
    "            return -1\n",
    "        for i in range(5, -1, -1):\n",
    "            if self.board[i][y] == '-':\n",
    "                self.board[i][y] = self.turn\n",
    "                return 1\n",
    "        return 0       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the gameplay, we can play PvP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "0 1 2 3 4 5 6\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - X - - -\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6928/1268922865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_pvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6928/1683763314.py\u001b[0m in \u001b[0;36mplay_pvp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misFinished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"It is now {self.turn}'s turn.\\nMake a move by choosing your coordinates to play:\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid move.\\nMake a move by choosing your coordinates to play:\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "a = Game()\n",
    "a.play_pvp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However there are a lot of changes required to make the \"AI\" work, to make, as the following:\n",
    "- Either the class is changed to sustain the new characters, or (our approach), replace explicitly on the dataframe, using \"replace()\" methods;\n",
    "\n",
    "- Make sure that the logical link between a line of the dataframe and an instance of the class is ensured;\n",
    "\n",
    "- The AI will consider our move in a Game instance. Then, it will consider the possible moves, using the *available_cols* method:\n",
    "  - it needs to get all the lines that have those moves placed;\n",
    "  - each line, each game is considered, to choose the next move, based on the IG and on the no of wins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Replace the values on the dataframe to adapt to our class\n",
    "\n",
    "The change of the column names was added in the beggining of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-5</th>\n",
       "      <th>0-4</th>\n",
       "      <th>0-3</th>\n",
       "      <th>0-2</th>\n",
       "      <th>0-1</th>\n",
       "      <th>0-0</th>\n",
       "      <th>1-5</th>\n",
       "      <th>1-4</th>\n",
       "      <th>1-3</th>\n",
       "      <th>1-2</th>\n",
       "      <th>...</th>\n",
       "      <th>5-2</th>\n",
       "      <th>5-1</th>\n",
       "      <th>5-0</th>\n",
       "      <th>6-5</th>\n",
       "      <th>6-4</th>\n",
       "      <th>6-3</th>\n",
       "      <th>6-2</th>\n",
       "      <th>6-1</th>\n",
       "      <th>6-0</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0-5 0-4 0-3 0-2 0-1 0-0 1-5 1-4 1-3 1-2  ... 5-2 5-1 5-0 6-5 6-4 6-3 6-2  \\\n",
       "0   -   -   -   -   -   -   -   -   -   -  ...   -   -   -   -   -   -   -   \n",
       "1   -   -   -   -   -   -   O   -   -   -  ...   -   -   -   -   -   -   -   \n",
       "2   -   -   -   -   -   -   -   -   -   -  ...   -   -   -   -   -   -   -   \n",
       "3   O   -   -   -   -   -   -   -   -   -  ...   -   -   -   -   -   -   -   \n",
       "4   -   -   -   -   -   -   -   -   -   -  ...   -   -   -   O   -   -   -   \n",
       "\n",
       "  6-1 6-0 result  \n",
       "0   -   -    win  \n",
       "1   -   -    win  \n",
       "2   -   -    win  \n",
       "3   -   -    win  \n",
       "4   -   -    win  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.replace({'o': 'O', 'x': 'X', 'b': '-'}, inplace=True)\n",
    "df4.drop('ID', axis=1, inplace=True)\n",
    "df4.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Replaced on the class, the __init __ to call the starting turn/board\n",
    "Changes made in place, no code here. Helped the debug phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Be able to instantiate a line of the dataframe into the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6\n",
      "- - - O - - -\n",
      "- - - X - - -\n",
      "- - - O - - -\n",
      "- - - X - - -\n",
      "- - - O - - -\n",
      "- - X X O - -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def matrix_from_df_line(l):\n",
    "    \"\"\"Return matrix given a dataframe line (Connect-4 only)\"\"\"\n",
    "    row_values = df4.iloc[l]\n",
    "\n",
    "    board_rows = 6\n",
    "    board_cols = 7\n",
    "    connect_4_board = np.full((board_rows, board_cols), '-')  \n",
    "\n",
    "    # Populate the matrix using column names\n",
    "    for col in df4.columns[1:-1]:\n",
    "        col_index, row_index = map(int, col.split('-'))   \n",
    "        connect_4_board[row_index, col_index] = row_values[col]\n",
    "\n",
    "    return connect_4_board.tolist()\n",
    "\n",
    "board_state = matrix_from_df_line(0)\n",
    "test_import = Game(board_state)\n",
    "test_import.printer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Be able to find all the lines that have a X (my turn) on the respective place\n",
    "\n",
    "Essentially, let's say I play on a new board state, in the column 3. We need all the lines in which I played there. To do so, we will use a sample of the dataframe containing the first 200 lines. \n",
    "\n",
    "(dps e preciso escolher based on that, o lugar nas colunas disponiveis que da mais winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
